{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "df = pd.read_csv(\"hotels_data.csv\")\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "#parsing string to date time format\n",
    "def get_datetime(date_str):\n",
    "    return datetime.strptime(date_str, '%m/%d/%Y %H:%M')\n",
    "\n",
    "df[\"DayDiff\"] = DataFrame([get_datetime(val) for val in df[\"Checkin Date\"]]) - DataFrame([get_datetime(val) for val in df[\"Snapshot Date\"]])\n",
    "df[\"WeekDay\"] = DataFrame([get_datetime(val).weekday() for val in df[\"Checkin Date\"]])\n",
    "df[\"DiscountDiff\"] = df[\"Original Price\"] - df[\"Discount Price\"]\n",
    "df[\"DiscountPerc\"] = (df[\"DiscountDiff\"]/df[\"Original Price\"]) * 100\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 150 common hotels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting and sorting by common hotel name\n",
    "df[\"Hotel_Count\"] = df.groupby('Hotel Name')['Hotel Name'].transform('count')\n",
    "descending_hotels = df.sort_values(by=['Hotel_Count'],ascending=False).reset_index()\n",
    "\n",
    "#getting first 150 hotels  \n",
    "df_hotels = descending_hotels[\"Hotel Name\"].unique()[:150]\n",
    "most_common_hotels = descending_hotels[descending_hotels['Hotel Name'].isin(df_hotels)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 40 checkins contain most lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting and sorting by common checking_data\n",
    "most_common_hotels[\"Checkin_Count\"] = most_common_hotels.groupby('Checkin Date')['Checkin Date'].transform('count')\n",
    "descending_most_common_hotels = most_common_hotels.sort_values(by=['Checkin_Count'],ascending=False).reset_index()\n",
    "\n",
    "#getting first 40 checkins  \n",
    "common_checkins_list = descending_most_common_hotels[\"Checkin Date\"].unique()[:40]\n",
    "most_checkins = descending_most_common_hotels[descending_most_common_hotels['Checkin Date'].isin(common_checkins_list)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating synthetic values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unique_hotels_names = most_checkins[\"Hotel Name\"].unique()\n",
    "unique_checkins =  most_checkins[\"Checkin Date\"].unique()\n",
    "unique_discount_code =  [1,2,3,4]\n",
    "\n",
    "#creating default data - all combination : checking -hotel - discount code\n",
    "import itertools\n",
    "import sys\n",
    "combs = []\n",
    "for x in unique_hotels_names:\n",
    "    for y in unique_checkins:\n",
    "        for z in unique_discount_code:\n",
    "            combs.append([x, y,z,sys.maxsize])\n",
    "\n",
    "# converting the default data to data frame and appending to existing\n",
    "new_df =  DataFrame.from_records(combs,columns=[\"Hotel Name\",\"Checkin Date\",\"Discount Code\",\"Discount Price\"])\n",
    "most_checkins = most_checkins.append(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the minimum values per Hotel Name - Checkin Date - Discount Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding minimum  discount price outa  hotel name - checking date - discount code group and fixing data\n",
    "most_checkins[\"Discount Price\"]= most_checkins.groupby(['Hotel Name','Checkin Date','Discount Code'])[\"Discount Price\"].transform('min')\n",
    "most_checkins.drop_duplicates(subset=[\"Hotel Name\",\"Checkin Date\",\"Discount Code\"], inplace=True)\n",
    "most_checkins.sort_values(by=[\"Hotel Name\",\"Checkin Date\",\"Discount Code\"],ascending=True,inplace=True)\n",
    "most_checkins['Discount Price'].replace(sys.maxsize, -1, inplace=True)\n",
    "\n",
    "# taking only needed data\n",
    "checkin_hotel_discount = most_checkins[[\"Hotel Name\",\"Checkin Date\",\"Discount Code\",\"Discount Price\"]].reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing only positive numbers, ignoring -1 values\n",
    "discount_filtered = checkin_hotel_discount[checkin_hotel_discount['Discount Price'] > -1 ]\n",
    "\n",
    "def normalize_data(x):\n",
    "    diff = max(x) - min(x)\n",
    "    if(diff == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return (round( ( x - min(x) ) / ( max(x) - min(x) ) * 100 ))\n",
    "\n",
    "discount_filtered_grouped = discount_filtered.groupby('Hotel Name')['Discount Price']\n",
    "discount_filtered[\"Normal\"] = discount_filtered_grouped.transform(normalize_data) \n",
    "\n",
    "discount_synth = checkin_hotel_discount[checkin_hotel_discount['Discount Price'] == -1 ]\n",
    "discount_synth[\"Normal\"] = -1\n",
    "\n",
    "#checkin_hotel_discount\n",
    "normal_dataFrame = discount_synth.append(discount_filtered)\n",
    "normal_dataFrame.sort_values(by=[\"Hotel Name\",\"Checkin Date\",\"Discount Code\"],ascending=True,inplace=True)\n",
    "normal_dataFrame\n",
    "\n",
    "\n",
    "# NOTES\n",
    "# We had an issue with N/A values.\n",
    "# There were few possiboles reasons for this problem.\n",
    "# One Posibility is that we had one row per hotel name (the rest were -1 and weren't included in this data frame ) and the calculate of max value less min value gave as zero.\n",
    "# Another posibility is that all the rows of the hotels were equal and the maximun and minimum value price were equal.\n",
    "# We solved this issue by checking if the maximum and minimum value of hotel names group by is 0, and return 0 and not calculating and dividing by 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# building list out of each value of hotel name\n",
    "rows = []\n",
    "def createRow(x):    \n",
    "    new_list = x.tolist()\n",
    "    new_list.insert(0,x.name)\n",
    "    rows.append(new_list)\n",
    "    \n",
    "#converting the list to multi-columns data frame\n",
    "normal_dataFrame.groupby(\"Hotel Name\")[\"Normal\"].transform( createRow )  # group by returns for each hotel a list of his normalized prices\n",
    "vector = pd.DataFrame.from_records(rows)\n",
    "\n",
    "# NOTES\n",
    "# Vector - each row represents a hotel along with his 160 normalized prices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Hierarchical  Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing clustering libaries \n",
    "from scipy.cluster.hierarchy import dendrogram, linkage \n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import cluster\n",
    "shc = cluster.hierarchy\n",
    "\n",
    "#preproccesing data for clustering\n",
    "labels = vector.values[:,0]\n",
    "data = vector.values[:,1:160]\n",
    "plt.figure(figsize=(20, 10))  \n",
    "plt.title(\"Clustering Hotels\")  \n",
    "\n",
    "# \"ward\" - minimizes the variance between clusters, that means that each two clusters were combine if their variance is close to each other \n",
    "Z = shc.linkage(data, method='ward')\n",
    "dend = shc.dendrogram(Z, labels=labels) \n",
    "plt.show(dend)\n",
    "\n",
    "\n",
    "# NOTES\n",
    "# The purpose of finding groups of hotels with similarity in their pricing policy is to be able \n",
    "# to break a vacation into multiple different hotels which gurantees a minimum price.\n",
    "# The naive solution is finding all the combinations for the desired date range.\n",
    "# An alternative way is finding the cheapest hotel for the desired date and \n",
    "# performing a naive search of all the combinations within the current hotel's cluster, instead of searching all the hotels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Hotel names to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "#running the algorithem again in a diffrent way\n",
    "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')  \n",
    "clusters = cluster.fit_predict(vector.values[:,1:160])  \n",
    "\n",
    "hotels = pd.DataFrame.from_records(vector.values)\n",
    "\n",
    "hotels[\"cluster\"] = clusters\n",
    "hotels = hotels[[0,\"cluster\"]]\n",
    "hotels.sort_values(by=[\"cluster\"],ascending=True,inplace=True)\n",
    "\n",
    "hotels[\"Count\"] = hotels.groupby(\"cluster\")[0].transform(\"count\")\n",
    "hotels\n",
    "\n",
    "# NOTES\n",
    "# In order to understand our data and get a cleaer picture of out data, we have mapped the hotel names to clusters in a data frame.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying clustering in a 2d scatter graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2).fit(data)\n",
    "pca_2d = pca.transform(data)\n",
    "\n",
    "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')  \n",
    "cluster.fit_predict(pca_2d)  \n",
    "\n",
    "plt.figure(figsize=(10, 7))  \n",
    "plt.scatter(pca_2d[:,0],pca_2d[:,1],c=cluster.labels_, cmap='rainbow')  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
