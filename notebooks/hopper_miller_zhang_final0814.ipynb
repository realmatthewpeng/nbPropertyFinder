{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shelter Animal Outcomes\n",
    "#### MIDS W207 Final Project\n",
    "#### Clay Miller, Roseanna Hopper, Yubo Zhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Approximately 6.5 to 7.6 million companion animals enter the animal shelters across the U.S. each year. Each year, approximately 1.5 million shelter animals are euthanized (670,000 dogs and 860,000 cats). The number of dogs and cats euthanized in U.S. shelters annually has declined from approximately 2.6 million in 2011. This decline can be partially explained by an increase in the percentage of animals adopted and an increase in the number of stray animals successfully returned to their owners.\n",
    "\n",
    "For this exploration, we are using a dataset of intake information including breed, color, sex, and age from the [Austin Animal Center](https://www.kaggle.com/c/shelter-animal-outcomes), to develop a model that can be used for shelters to predict the outcome for each animal.  We are hoping that by using this model, the shelter can provide a little bit of extra help for animals that have a low adoption rate. In addition, we are hoping this dataset can help us to provide some key findings (for example, if age and gender would impact the adoption rate for dogs, if neutered or spayed cats are more likely to be adopted), understand which factors impact the chance of adoption, and identify differences between dog and cat adoption trends.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import tensorflow \n",
    "import keras\n",
    "import itertools\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import FeatureHasher, DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from bokeh.charts import Bar, output_file, show, output_notebook\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from IPython.core.display import Image, display\n",
    "from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image  \n",
    "from sklearn import tree\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data\n",
    "\n",
    "Each case in our raw training data is an individual animal, and the features include its characteristics (including name, animal type, age, gender, spay/neuter status, breed, coloring, and final outcome). Apart from age, all of the fields are categorical variables, so we’ll be creating binary variables for the majority of the fields (and their intersections). There are few missing values, and some cases where a field is marked as “Unknown” (appears in Name, Breed, and Gender). Overall, we are trying to predict the animal’s “final outcome”, of which there are five possibilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('../data/train.csv')\n",
    "breeds = pd.read_csv('../data/breeds.csv')\n",
    "breeds['Breed'] = breeds['Breed'].str.strip()\n",
    "top_breed_list = []\n",
    "for b in breeds['Breed']:\n",
    "    top_breed_list.append(b.strip())\n",
    "data['OutcomeSubtype'] = data['OutcomeSubtype'].fillna('')\n",
    "data['Female'] = 'Female' in data['SexuponOutcome']\n",
    "data['AgeuponOutcome'].fillna('', inplace = True)\n",
    "\n",
    "#Create a continuous variable for age, making sure\n",
    "#that all listed ages are on the same scale (months)\n",
    "def ageConvert(age):\n",
    "    regexyear = '(\\d+) year'\n",
    "    regexmnth = '(\\d+) month'\n",
    "    regexwk = '(\\d+) week'\n",
    "    regexday = '(\\d+) day'\n",
    "    if re.match(regexyear, age):\n",
    "        const = int(re.match(regexyear, age).groups()[0])\n",
    "        return const*52\n",
    "    elif re.match(regexmnth, age):\n",
    "        const = int(re.match(regexmnth, age).groups()[0])\n",
    "        return const*4.5 # a month is roughly 4.5 weeks\n",
    "    elif re.match(regexwk, age):\n",
    "        return int(re.match(regexwk, age).groups()[0])\n",
    "    elif re.match(regexday, age):\n",
    "        const = int(re.match(regexday, age).groups()[0])\n",
    "        return const/7 #7 days in a week\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "data['ConvertedAge']=data['AgeuponOutcome'].apply(ageConvert)\n",
    "\n",
    "\n",
    "#Separate SexuponOutcome into Male/Female and into Intact/Spayed-Neutered\n",
    "def female(i):\n",
    "    i = str(i)\n",
    "    if i.find('Female') >= 0: return 'Female'\n",
    "    if i.find('Unknown') >= 0: return 'Unknown'\n",
    "    return 'Male'\n",
    "data['Female'] = data.SexuponOutcome.apply(female)\n",
    "\n",
    "def intact(i):\n",
    "    i = str(i)\n",
    "    if i.find('Intact') >= 0: return 'Intact'\n",
    "    if i.find('Unknown') >= 0: return 'Unknown'\n",
    "    return 'Spayed/Neutered'\n",
    "data['Intact'] = data.SexuponOutcome.apply(intact)\n",
    "\n",
    "def mixed_breed(i):\n",
    "    i = str(i)\n",
    "    if i.find('Mix') >= 0: return 'Mixed Breed'\n",
    "    if i.find('/') >= 0: return 'Known Breed Combo'\n",
    "    return 'Nonmixed'\n",
    "data['MixedBreed'] = data.Breed.apply(mixed_breed)\n",
    "\n",
    "def top_breed(i):\n",
    "    i = str(i)\n",
    "    if any(word in i for word in top_breed_list):\n",
    "        return int(1)\n",
    "    else:\n",
    "        return int(0)\n",
    "data['TopBreed'] = data.Breed.apply(top_breed)\n",
    "\n",
    "def breed_rank(i):\n",
    "    i = str(i)\n",
    "    ranks = []\n",
    "    for word in top_breed_list:\n",
    "        if word in i:\n",
    "            ranks.append(int(breeds.loc[breeds['Breed'] == word]['2007']))\n",
    "    if len(ranks) > 0:\n",
    "        return np.mean(ranks)\n",
    "    else:\n",
    "        return 51.0\n",
    "data['BreedRank'] = data.Breed.apply(breed_rank)\n",
    "\n",
    "def pit_bull(i):\n",
    "    i = str(i)\n",
    "    if i.find(\"Pit Bull\") >=0: return int(1)\n",
    "    else: return int(0)\n",
    "data['PitBull'] = data.Breed.apply(pit_bull)\n",
    "\n",
    "def black_cat(i):\n",
    "    i = str(i)\n",
    "    if i == \"Black\": return int(1)\n",
    "    else: return int(0)\n",
    "data['BlackCat'] = data.Color.apply(black_cat)\n",
    "\n",
    "def naming(i):\n",
    "    if pd.isnull(i): return 'Unnamed'\n",
    "    return 'Named'\n",
    "data['Named'] = data.Name.apply(naming)\n",
    "\n",
    "#Change all breed and color strings so that they are ordered consistently\n",
    "#E.G. all \"brown/black\" and \"black/brown\" should become \"black, brown\"\n",
    "def reorder(i):\n",
    "    i = str(i)\n",
    "    if i.find(\" \") >= 0: i = i.replace(\" \", \"-\")\n",
    "    if i.find(\"/\") >= 0: i = i.replace(\"/\", \" \")\n",
    "    i = i.split()\n",
    "    i = sorted(i)\n",
    "    i = ' '.join(i)\n",
    "    return i\n",
    "\n",
    "data['OrderedColor'] = data.Color.apply(reorder)\n",
    "data['OrderedBreed'] = data.Breed.apply(reorder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Importing this because multiple deprecation warnings cluttering the output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "continuous = ['ConvertedAge', 'BreedRank']\n",
    "discrete = [\n",
    "    'AnimalType',\n",
    "    'Female',\n",
    "    'Intact',\n",
    "    'MixedBreed',\n",
    "    'Named',\n",
    "    'TopBreed',\n",
    "    'PitBull',\n",
    "    'BlackCat'\n",
    "]\n",
    "target = 'OutcomeType'\n",
    "\n",
    "#For those missing an age, fill with the median age by animal type\n",
    "data[\"ConvertedAge\"] = data.groupby(\"AnimalType\").transform(lambda x: x.fillna(x.median()))\n",
    "data[continuous].describe().T\n",
    "\n",
    "#Turn categorical variables into binaries\n",
    "data2 = pd.concat([data[target], data[continuous], pd.get_dummies(data[discrete])], axis=1)\n",
    "\n",
    "discrete = ['AnimalType_Cat', 'AnimalType_Dog', 'Female_Female', 'Female_Male', 'Female_Unknown',\n",
    "           'Intact_Intact', 'Intact_Spayed/Neutered', 'Intact_Unknown', 'MixedBreed_Known Breed Combo',\n",
    "           'MixedBreed_Mixed Breed', 'MixedBreed_Nonmixed', 'Named_Named', 'Named_Unnamed']\n",
    "\n",
    "\n",
    "predictors = continuous + discrete\n",
    "target = 'OutcomeType'\n",
    "\n",
    "\n",
    "# Train/test split on the full dataset\n",
    "X = data2[predictors]\n",
    "y = data2[[target]]\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, random_state=2)\n",
    "\n",
    "#Normalize the continuous variables\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train[continuous])   # Compute mean and std of training data\n",
    "X_train[continuous] = ss.transform(X_train[continuous])  # Use that mean and std to normalize columns of training data\n",
    "X_dev[continuous] = ss.transform(X_dev[continuous]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define continuous and categorical variables\n",
    "\n",
    "continuous = {'dog':['ConvertedAge', 'BreedRank'], 'cat':['ConvertedAge']}\n",
    "discrete = {'dog':[\n",
    "    'AnimalType',\n",
    "    'Female',\n",
    "    'Intact',\n",
    "    'MixedBreed',\n",
    "    'Named',\n",
    "    'TopBreed',\n",
    "    'PitBull'\n",
    "], 'cat': [\n",
    "    'AnimalType',\n",
    "    'Female',\n",
    "    'Intact',\n",
    "    'MixedBreed',\n",
    "    'Named',\n",
    "    'BlackCat'\n",
    "]}\n",
    "\n",
    "\n",
    "pred = {'dog': continuous['dog'] + discrete['dog'], 'cat':continuous['cat']+discrete['cat']}\n",
    "target = 'OutcomeType'\n",
    "\n",
    "#For those missing an age, fill with the median age by animal type\n",
    "data[\"ConvertedAge\"] = data.groupby(\"AnimalType\").transform(lambda x: x.fillna(x.median()))\n",
    "print data[continuous['dog']].describe().T\n",
    "print data[continuous['cat']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Turn categorical variables into binaries, eliminating unconverted columns\n",
    "data2_dog = pd.concat([data[target], data[continuous['dog']], pd.get_dummies(data[discrete['dog']])], axis=1)\n",
    "data2_cat = pd.concat([data[target], data[continuous['cat']], pd.get_dummies(data[discrete['cat']])], axis=1)\n",
    "print data2_dog.shape\n",
    "print data2_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split the data into cat and dog data sets\n",
    "data2_dog = pd.concat([data[target], data[continuous['dog']], pd.get_dummies(data[discrete['dog']])], axis=1)\n",
    "data2_cat = pd.concat([data[target], data[continuous['cat']], pd.get_dummies(data[discrete['cat']])], axis=1)\n",
    "\n",
    "discrete_dog = ['AnimalType_Cat', 'AnimalType_Dog', 'Female_Female', 'Female_Male', 'Female_Unknown',\n",
    "           'Intact_Intact', 'Intact_Spayed/Neutered', 'Intact_Unknown', 'MixedBreed_Known Breed Combo',\n",
    "           'MixedBreed_Mixed Breed', 'MixedBreed_Nonmixed', 'Named_Named', 'Named_Unnamed', 'TopBreed', 'PitBull']\n",
    "\n",
    "discrete_cat = ['AnimalType_Cat', 'AnimalType_Dog', 'Female_Female', 'Female_Male', 'Female_Unknown',\n",
    "           'Intact_Intact', 'Intact_Spayed/Neutered', 'Intact_Unknown', 'MixedBreed_Known Breed Combo',\n",
    "           'MixedBreed_Mixed Breed', 'MixedBreed_Nonmixed', 'Named_Named', 'Named_Unnamed', 'BlackCat']\n",
    "\n",
    "predictors_dog = continuous['dog'] + discrete_dog\n",
    "predictors_cat = continuous['cat'] + discrete_cat\n",
    "\n",
    "# Train/test split\n",
    "X_dog = data2_dog[data2_dog['AnimalType_Dog'] == 1][predictors_dog]\n",
    "y_dog = data2_dog[data2_dog['AnimalType_Dog'] == 1][[target]]\n",
    "X_dog_train, X_dog_dev, y_dog_train, y_dog_dev = train_test_split(X_dog, y_dog, random_state=2)\n",
    "\n",
    "X_cat = data2_cat[data2_cat['AnimalType_Cat'] == 1][predictors_cat]\n",
    "y_cat = data2_cat[data2_cat['AnimalType_Cat'] == 1][[target]]\n",
    "X_cat_train, X_cat_dev, y_cat_train, y_cat_dev = train_test_split(X_cat, y_cat, random_state=2)\n",
    "\n",
    "#Normalize \n",
    "ss_dog = StandardScaler()\n",
    "ss_dog.fit(X_dog_train[continuous['dog']])   # Compute mean and std of training data\n",
    "X_dog_train[continuous['dog']] = ss_dog.transform(X_dog_train[continuous['dog']])  # Use that mean and std to normalize columns of training data\n",
    "X_dog_dev[continuous['dog']] = ss_dog.transform(X_dog_dev[continuous['dog']]) \n",
    "print X_dog.shape\n",
    "\n",
    "ss_cat = StandardScaler()\n",
    "ss_cat.fit(X_cat_train[continuous['cat']])   # Compute mean and std of training data\n",
    "X_cat_train[continuous['cat']] = ss_cat.transform(X_cat_train[continuous['cat']])  # Use that mean and std to normalize columns of training data\n",
    "X_cat_dev[continuous['cat']] = ss_cat.transform(X_cat_dev[continuous['cat']]) \n",
    "print X_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Features\n",
    "\n",
    "- We have approximately the same number of cats and dogs.\n",
    "- The majority of animals are adopted or transferred; there are comparatively few cases of death or euthanasia.\n",
    "- As we would expect, the majority of cases would be considered mixed breed. Also expected is that there are few animals beyond 15 years old.\n",
    "- A large majority of animals are named (though whether by the shelter or a prior owner is unknown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Animal types\n",
    "animal_type = data['AnimalType'].value_counts() \n",
    "animal_type.plot(kind='bar',color='#34ABD8',rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Outcome types\n",
    "outcome_type = data['OutcomeType'].value_counts() \n",
    "outcome_type.plot(kind='bar',color='#34ABD8',rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = Bar(data, label='OutcomeType', values = 'Intact', agg='count', stack='Intact',\n",
    "        title=\"Outcomes by Intact Status\", legend='top_right')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = Bar(data, label='OutcomeType', values = 'Female', agg='count', stack='Female',\n",
    "        title=\"Outcomes by Female\", legend='top_right')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = Bar(data, label='OutcomeType', values = 'MixedBreed', agg='count', stack='MixedBreed',\n",
    "        title=\"Outcomes by Breed Type\", legend='top_right')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Age of animals\n",
    "data.hist(column=\"ConvertedAge\", bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = Bar(data, label='OutcomeType', values = 'Named', agg='count', stack='Named',\n",
    "        title=\"Outcomes by Name Status\", legend='top_right')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OrderedBreed = data.OrderedBreed.unique()\n",
    "print(\"Unique Breeds\" , (data.OrderedBreed.value_counts() > 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot visualized correlation matrix\n",
    "def plot_corr(data,size=20):\n",
    "    corr = data.corr()\n",
    "    fig, ax = plt.subplots(figsize=(25, 25))\n",
    "    cax = ax.matshow(corr)\n",
    "    fig.colorbar(cax)\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns,rotation='vertical');\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns);\n",
    "    plt.show()\n",
    "plot_corr(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the most interesting findings here:  \n",
    "- As we would expect, being spayed/neutered is moderately correlated with being named.\n",
    "- There is a weak positive correlation between being spayed/neutered and being a cat.\n",
    "- Between variables that aren't obviously or artificially related (like being a dog and being a pitbull), there are few relationships that could be characterized as more than moderately correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Should dogs and cats be modeled separately?\n",
    "\n",
    "- It appears that although cats and dogs in this dataset are adopted or transferred at similar rates, dogs have a much higher rate of returning to owner, so it may be advisable to separate the models by animal type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Animal types\n",
    "p = Bar(data, label='OutcomeType', values = 'AnimalType', agg='count', stack='AnimalType',\n",
    "        title=\"Outcomes by Animal Type\", legend='top_right')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Logistic Regression Exploration\n",
    "\n",
    "- With more than 26,000 cases, we have a more than adequate sample size for modeling.\n",
    "- By their nature, the classes within the dependent variable (OutcomeType) should be independent of one another.\n",
    "- Based on our correlation matrix, we should have no significant issues with multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Animal Type\n",
    "\n",
    "We'll start by checking how dogs and cats perform in separate models, also using GridSearch to determine the best regularization strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Find the best regularization strength\n",
    "      #Generate logistic regression\n",
    "def logit_reg(X_train, X_dev, y_train, y_dev, predict_anim):\n",
    "    logit_reg = LogisticRegression(penalty=\"l2\", multi_class='multinomial', solver='newton-cg')  \n",
    "    print X_train.shape\n",
    "    print type(pd.Series(y_train))\n",
    "    y_train = y_train.values.ravel()\n",
    "    y_dev = y_dev.values.ravel()\n",
    "    \n",
    "    #Test C within [0.001, 10]\n",
    "    param_domain = [0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 5.0, 10.0]\n",
    "    param_dict = dict(C = param_domain)\n",
    "    print param_dict\n",
    "\n",
    "    #Initialize GridSearchCV to identify the optimal parameter values\n",
    "    gridsearch = GridSearchCV(logit_reg, param_dict)\n",
    "    gridsearch.fit(X_train, y_train)\n",
    "\n",
    "    #Generate model at the best C value\n",
    "    C = gridsearch.best_params_[\"C\"]\n",
    "    print \"Train data: Logistic Regression score at C=%.3f: %f\" % (C, gridsearch.best_score_)\n",
    "    print ('\\n' * 1)\n",
    "    logit_reg = LogisticRegression(C=C, penalty=\"l2\")\n",
    "    logit_reg.fit(X_train, y_train)\n",
    "\n",
    "    #Predict on the X_dev set\n",
    "    logit_reg_dev = logit_reg.predict(X_dev)\n",
    "\n",
    "    #Generate classification report\n",
    "    print \"Classification Report:\"\n",
    "    print \" \"\n",
    "    print classification_report(y_dev, logit_reg_dev, target_names=logit_reg.classes_)\n",
    "    print \"Dev data: Logistic Regression score at C=%.3f: %f\" % (C, metrics.f1_score(y_dev, logit_reg_dev, average=\"weighted\"))    \n",
    "    print \"Weights:\"\n",
    "    #Get the variables with the highest weights for each outcome\n",
    "    print logit_reg.classes_\n",
    "    weights = []\n",
    "    for i in range(len(logit_reg.classes_)):\n",
    "        top_vars = np.argsort(logit_reg.coef_[i])[-6:-1]\n",
    "        print logit_reg.classes_[i]\n",
    "        for j in top_vars:\n",
    "            print predict_anim[j], round(logit_reg.coef_[i][j],3)\n",
    "        print\n",
    "    print ('\\n' * 2)\n",
    "\n",
    "\n",
    "    #Generate logistic regression and add the squared weight values to an array, at each C\n",
    "    logit_reg_coeff = []\n",
    "    for c in param_domain:\n",
    "        logit_reg = LogisticRegression(C=c, penalty=\"l2\") \n",
    "        logit_reg.fit(X_train, y_train)\n",
    "        squared_weights = []\n",
    "        squared_weights.append(c)                       \n",
    "        for i in range(0, 4):\n",
    "            [squared_weights.append(np.sum(np.power(logit_reg.coef_[i], 2)))]\n",
    "        logit_reg_coeff.append(squared_weights)\n",
    "\n",
    "    coeff = np.asarray(logit_reg_coeff, dtype = \"object\")\n",
    "\n",
    "print 'Logistic Regression: Dogs Only'\n",
    "logit_reg(X_dog_train, X_dog_dev, y_dog_train, y_dog_dev, predictors_dog)\n",
    "print 'Logistic Regression: Cats Only'\n",
    "logit_reg(X_cat_train, X_cat_dev, y_cat_train, y_cat_dev, predictors_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the highest training accuracy on the dog-only model at 0.56 and the highest accuracy for cats at 0.74, here we see further evidence that cats and dogs should be modeled separately.\n",
    "\n",
    "The model weights also yield some interesting results; note that the factors we thought might be important and highly weighted are not. For instance, we assumed that the breed would have played a much larger role in the outcome. Also of note is that in the dog model, the variable AnimalType_Cat - that is, whether or not the animal is a cat - has a higher weight than some other factors. This is the dog data though, so this should be a meaningless column in terms of outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Logistic Regression Pipeline\n",
    "\n",
    "Here we'll define a pipeline to binarize the categorical variables, scale the continuous variables, and fit a logistic regression; we're creating different models for dogs and cats so we'll define separate pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reset train/test split with pred\n",
    "data_dog = data[data['AnimalType'] == 'Dog']\n",
    "data_cat = data[data['AnimalType'] == 'Cat']\n",
    "X_dog = data_dog[pred['dog']]\n",
    "X_cat = data_cat[pred['cat']]\n",
    "y_dog = data_dog[[target]]\n",
    "y_cat = data_cat[[target]]\n",
    "X_dog_train, X_dog_dev, y_dog_train, y_dog_dev = train_test_split(X_dog, y_dog, random_state=2)\n",
    "X_cat_train, X_cat_dev, y_cat_train, y_cat_dev = train_test_split(X_cat, y_cat, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyVectorizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols, hashing=None):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            cols: a list of column names of the categorical variables\n",
    "            hashing: \n",
    "                If None, then vectorization is a simple one-hot-encoding.\n",
    "                If an integer, then hashing is the number of features in the output.\n",
    "        \"\"\"\n",
    "        self.cols = cols\n",
    "        self.hashing = hashing\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        data = X[self.cols]\n",
    "        \n",
    "        # Choose a vectorizer\n",
    "        if self.hashing is None:\n",
    "            self.myvec = DictVectorizer(sparse=False)\n",
    "        else:\n",
    "            self.myvec = FeatureHasher(n_features = self.hashing)\n",
    "    \n",
    "        self.myvec.fit(X[self.cols].to_dict(orient='records'))\n",
    "        return self\n",
    "            \n",
    "    def transform(self, X):\n",
    "            \n",
    "        # Vectorize Input\n",
    "        if self.hashing is None:\n",
    "            return pd.DataFrame(\n",
    "                self.myvec.transform(X[self.cols].to_dict(orient='records')),\n",
    "                columns = self.myvec.feature_names_\n",
    "            )\n",
    "        else:\n",
    "            return pd.DataFrame(\n",
    "                self.myvec.transform(X[self.cols].to_dict(orient='records')).toarray()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyScaler():\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.ss = StandardScaler()\n",
    "        self.ss.fit(X[self.cols])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.ss.transform(X[self.cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set the pipelines for categorical variables\n",
    "discrete_pipe_dog = Pipeline(steps=[('Vectorizer', MyVectorizer(cols=discrete['dog'], hashing=None))])\n",
    "discrete_pipe_cat = Pipeline(steps=[('Vectorizer', MyVectorizer(cols=discrete['cat'], hashing=None))])\n",
    "\n",
    "#Set the pipelines for continuous variables\n",
    "continuous_pipe_cat = Pipeline(steps=[('Scale', MyScaler(continuous['cat']))])\n",
    "continuous_pipe_dog = Pipeline(steps=[('Scale', MyScaler(continuous['dog']))])\n",
    "\n",
    "#Bring the discrete and continuous pipelines together for cats and dogs\n",
    "union_dog = FeatureUnion([('Discrete', discrete_pipe_dog), ('Continuous', continuous_pipe_dog)])\n",
    "union_cat = FeatureUnion([('Discrete', discrete_pipe_cat), ('Continuous', continuous_pipe_cat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Full pipelines, using the best regularization strengths for the dog and cat models, respectively\n",
    "pipeline_dog = Pipeline([('Preprocess', FeatureUnion([('Discrete', discrete_pipe_dog), ('Continuous', continuous_pipe_dog)])),\n",
    "                      ('Predict', LogisticRegression(multi_class='multinomial', C=0.25, solver='newton-cg'))])\n",
    "pipeline_cat = Pipeline([('Preprocess', FeatureUnion([('Discrete', discrete_pipe_cat), ('Continuous', continuous_pipe_cat)])),\n",
    "                      ('Predict', LogisticRegression(multi_class='multinomial', C=0.10, solver='newton-cg'))])\n",
    "\n",
    "#Fit the multinomial logistic regression for dogs and cats, respectively\n",
    "test_dog_lr = pipeline_dog.fit(X_dog_train, y_dog_train)\n",
    "test_cat_lr = pipeline_cat.fit(X_cat_train, y_cat_train)\n",
    "\n",
    "print \"Dogs: Multinomial Logistic Regression Train Accuracy :: \", metrics.accuracy_score(y_dog_train, test_dog_lr.predict(X_dog_train))\n",
    "print \"Dogs: Multinomial Logistic Regression Dev Accuracy :: \", metrics.accuracy_score(y_dog_dev, test_dog_lr.predict(X_dog_dev))\n",
    "print\n",
    "print \"Cats: Multinomial Logistic Regression Train Accuracy :: \", metrics.accuracy_score(y_cat_train, test_cat_lr.predict(X_cat_train))\n",
    "print \"Cats: Multinomial Logistic Regression Dev Accuracy :: \", metrics.accuracy_score(y_cat_dev, test_cat_lr.predict(X_cat_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize = False, title = 'Confusion Matrix', cmap = plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "class_names = ['Return_to_owner', 'Euthanasia', 'Adoption', 'Transfer', 'Died']\n",
    "cnf_dog_matrix = confusion_matrix(y_dog_dev, test_dog_lr.predict(X_dog_dev), labels = class_names)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_dog_matrix, classes=class_names, normalize = True,\n",
    "                      title='Confusion matrix for Dogs, with normalization')\n",
    "\n",
    "cnf_cat_matrix = confusion_matrix(y_cat_dev, test_cat_lr.predict(X_cat_dev), labels = class_names)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_cat_matrix, classes=class_names, normalize = True,\n",
    "                      title='Confusion matrix for Cats, with normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in performance between the dog and cat models is interesting, but the confusion matrices can tell us a bit about where the models are going wrong.\n",
    "\n",
    "Dogs:  \n",
    "- Though a majority of the Adoption cases are predicted correctly, performance falls off sharply to the second-best category (Transfer).\n",
    "- The majority of Return To Owner cases are incorrectly identified as Adoption, and the same is true for Transfer.\n",
    "- There appear to be no successful Died predictions, with the majority going to Transfer.\n",
    "- Euthanasia is similarly unsuccessful as a prediction.\n",
    "\n",
    "Cats:\n",
    "- The disparity between the best and second-best categories (still Adoption and Transfer) is less sharp here.\n",
    "- The poor Return to Owner prediction rate in dogs is even worse in cats; the majority are predicted to be Adoption.\n",
    "- Died and Euthanasia are more often flagged as Transfer than any other category.\n",
    "\n",
    "A large part of the issue may be the comparatively small n sizes for the outcomes other than Adoption and Transfer. It appears that when so many cases have an adoption outcome, the model rewards erroneously predicting the adoption outcome - particularly so for dogs.\n",
    "\n",
    "For both dogs and cats, we see poor predictive power in the Died and Euthanasia categories. It seems likely that, beyond the distributions in the sample data, there are confounding factors that can't be captured with the data we have. For example, an animal that appears likely for Transfer based on these features may actually be euthanized due to health or temperament conditions outside of what is identifiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Classification Report: Dogs\")\n",
    "print(classification_report(y_dog_dev, test_dog_lr.predict(X_dog_dev), target_names=class_names))\n",
    "print '\\n'\n",
    "\n",
    "print(\"Classification Report: Cats\")\n",
    "print(classification_report(y_cat_dev, test_cat_lr.predict(X_cat_dev), target_names=class_names))\n",
    "print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the classification reports show a similar story.\n",
    "\n",
    "Though the cat model performs better overall, it performs quite poorly on Transfer prediction, with only 7% of Transfers being identified correctly. We see a fairly high precision for Died in both models, most likely because of so few positive cases being represented in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Exploration\n",
    "\n",
    "As an alternative to logistic regression, we will use Keras for neural network modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using keras to predict outcome\n",
    "from keras.layers import Dropout\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(15,)),\n",
    "    Dropout(0.1),   # Added a dropout layer of 10% to regulate neural network\n",
    "    Activation('sigmoid'),\n",
    "    Dense(5),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(np.array(X_train), y_train_hot, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(np.array(X_dev), y_dev_hot, batch_size=16)\n",
    "\n",
    "print '\\nAccuracy on test data', score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "On a simple model with combined data, we see that the overall accuracy has improved over the logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminating unknown columns \n",
    "Now we'll try a more limited dataset, eliminating unknown gender and unknown intactness to see if the new dataset can give a better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_feature = X_train\n",
    "X_train_feature = X_train_feature.drop('Intact_Unknown', 1)\n",
    "X_train_feature = X_train_feature.drop('Female_Unknown', 1)\n",
    "X_dev_feature = X_dev\n",
    "X_dev_feature = X_dev_feature.drop('Intact_Unknown', 1)\n",
    "X_dev_feature = X_dev_feature.drop('Female_Unknown', 1)\n",
    "\n",
    "model2 = Sequential([\n",
    "    Dense(32, input_shape=(13,)),\n",
    "    Dropout(0.1),   \n",
    "    Activation('sigmoid'),\n",
    "    Dense(5),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model2.fit(np.array(X_train_feature), y_train_hot, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score2 = model2.evaluate(np.array(X_dev_feature), y_dev_hot, batch_size=16)\n",
    "\n",
    "print '\\nAccuracy on new dataset with no unknown columns is', score2[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that by eliminating the unknown gender and intactness columns, the new model's accuracy is slightly higher than the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing a Cat-Only Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_dog = X_train_feature\n",
    "X_train_dog = X_train_feature.drop('AnimalType_Dog', 1)\n",
    "X_dev_dog = X_dev_feature\n",
    "X_dev_dog = X_dev_feature.drop('AnimalType_Dog', 1)\n",
    "\n",
    "model3 = Sequential([\n",
    "    Dense(32, input_shape=(12,)),\n",
    "    Dropout(0.1),  \n",
    "    Activation('sigmoid'),\n",
    "    Dense(5),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model3.fit(np.array(X_train_dog), y_train_hot, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score3 = model3.evaluate(np.array(X_dev_dog), y_dev_hot, batch_size=16)\n",
    "\n",
    "print '\\nAccuracy on new dataset with only cat data is', score3[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing a Dog-Only Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_cat = X_train_feature\n",
    "X_train_cat = X_train_feature.drop('AnimalType_Cat', 1)\n",
    "X_dev_cat = X_dev_feature\n",
    "X_dev_cat = X_dev_feature.drop('AnimalType_Cat', 1)\n",
    "\n",
    "model4 = Sequential([\n",
    "    Dense(32, input_shape=(12,)),\n",
    "    Dropout(0.1),   \n",
    "    Activation('sigmoid'),\n",
    "    Dense(5),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "model4.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model4.fit(np.array(X_train_cat), y_train_hot, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score4 = model4.evaluate(np.array(X_dev_cat), y_dev_hot, batch_size=16)\n",
    "\n",
    "print '\\nAccuracy on new dataset with only dog data is', score4[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the new dataset with only cat data has slightly higher accuracy (0.8634) than only dog data (0.8630), but the biggest takeaway is that the NN models increase performance substantially over the logistic models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import test data and process for dog and cat subsets\n",
    "\n",
    "#Predict dog and cat outcomes on the test data using the final chosen models\n",
    "\n",
    "#Write to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering\n",
    "\n",
    "We're beginning with a simple multinomial logistic regression, which we will use to test combinations of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Tested for C in 0.00001, 0.0001, 0.001, 0.01, 0.1,, 1.0, 2.0, 4.0, 6.0, 8.0, 10.0\n",
    "#Highest accuracy is when C=0.5\n",
    "\n",
    "for m in [0.5]: # 0.00001, 0.0001, 0.001, 0.01, 0.1,, 1.0, 2.0, 4.0, 6.0, 8.0, 10.0\n",
    "    lrq = LogisticRegression(C = m, penalty = 'l2')\n",
    "    lrq.fit(X_train, y_train)\n",
    "    weight1 = lrq.coef_\n",
    "    sum1 = sum(sum(weight1))\n",
    "    print 'Accuracy at C=0.5:', lrq.score(X_dev, y_dev)\n",
    "    print 'Sum of Squared Weight:', sum1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset, we have 15 different features, including gender, breed, age, and so on.  In order to select the best\n",
    "features to add to the model, here we select features from the bottom up, starting from only 1 feature and adding more features based on the accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Importing this because of deprecation warnings cluttering the output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Start the bottom up feature selection\n",
    "# Compute the accuracy of logistic regression with N features\n",
    "\n",
    "train = X_train\n",
    "dev = X_dev\n",
    "\n",
    "bestVec = [] \n",
    "\n",
    "for j in range(15):\n",
    "    maxacc = 0\n",
    "    maxi = 0\n",
    "    for i in range(15):\n",
    "        if i not in bestVec:\n",
    "            X_train_eng = pd.DataFrame(train.ix[:, bestVec + [i]])\n",
    "            X_dev_eng = pd.DataFrame(dev.ix[:, bestVec + [i]])\n",
    "            m=0.5\n",
    "            lrq = LogisticRegression(C = m, penalty = 'l2')\n",
    "            lrq.fit(X_train_eng, y_train)\n",
    "            if lrq.score(X_dev_eng, y_dev) > maxacc:\n",
    "                maxacc = lrq.score(X_dev_eng, y_dev)\n",
    "                maxi = i\n",
    "    bestVec = bestVec + [maxi]\n",
    "    print 'At number of features =', j+1,'the best feature to add is', predictors[maxi],'and the accuracy is %.10f' % maxacc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on accuracy (highest 0.6347448751) and parsimony, the best model includes six features: Intact_Spayed/Neutered, ConvertedAge, AnimalType_Cat, MixedBreed_Known Breed Combo, Named_Unnamed, and MixedBreed_Nonmixed.\n",
    "\n",
    "However, further tests of this truncated dataset return lower accuracy overall, and were not used in the final modeling."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
