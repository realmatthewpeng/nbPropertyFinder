{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regression Models \n",
    "\n",
    "**Variables/Columns**\n",
    "\n",
    "- `Age` - years\n",
    "- `5K etc. Duration` - seconds\n",
    "- `Temp` - Degrees Fahrenheit\n",
    "- `Height` - inches\n",
    "- `M/F` - Male or Female\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the csv file into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = pd.read_csv('marathon/Boston_Marathon_2015_to_2017.csv')\n",
    "#boston.head()\n",
    "#boston.shape\n",
    "boston.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Pandas get_dummies to convert categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-41760f7611f17b25",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# convert male/female to 0/1s\n",
    "\n",
    "boston_mf=pd.get_dummies(boston['M/F'])\n",
    "\n",
    "# join the two dataframes\n",
    "\n",
    "boston_join=pd.concat([boston, boston_mf], axis=1) \n",
    "\n",
    "boston_join.head()\n",
    "# boston_join[['5K','10K','15K','20K','Half', '25K','30K']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_join.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert HH:MM:SS to total seconds\n",
    "\n",
    "def time_convert(x):\n",
    "    if x == \"-\":\n",
    "        return None\n",
    "    else:\n",
    "        times = x.split(':')\n",
    "        return (3600*int(times[0])+60*int(times[1]))+int(times[2])\n",
    "\n",
    "\n",
    "boston_join['5K Duration'] = boston_join['5K'].apply(time_convert)\n",
    "boston_join['10K Duration'] = boston_join['10K'].apply(time_convert)\n",
    "boston_join['15K Duration'] = boston_join['15K'].apply(time_convert)\n",
    "boston_join['20K Duration'] = boston_join['20K'].apply(time_convert)\n",
    "boston_join['Half Duration'] = boston_join['Half'].apply(time_convert)\n",
    "boston_join['25K Duration'] = boston_join['25K'].apply(time_convert)\n",
    "boston_join['30K Duration'] = boston_join['30K'].apply(time_convert)\n",
    "boston_join['35K Duration'] = boston_join['35K'].apply(time_convert)\n",
    "boston_join['40K Duration'] = boston_join['40K'].apply(time_convert)\n",
    "boston_join['Official Time Duration'] = boston_join['Official Time'].apply(time_convert)\n",
    "\n",
    "# Drop rows with null values\n",
    "\n",
    "boston_join.dropna(inplace=True,subset=['Bib','Age','5K Duration','10K Duration','15K Duration','20K Duration', 'Half Duration', '25K Duration','30K Duration','35K Duration','40K Duration','Official Time Duration', 'Temp (F)'])\n",
    "\n",
    "boston_clean=boston_join[['Bib','Age','5K Duration','10K Duration','15K Duration','20K Duration', 'Half Duration', '25K Duration','30K Duration','35K Duration','40K Duration','Official Time Duration', 'Temp (F)', 'F', 'M']]\n",
    "\n",
    "# boston_clean[['Bib','5K Duration','10K Duration','15K Duration','20K Duration','Half Duration', '25K Duration','30K Duration','Official Time Duration']]\n",
    "\n",
    "boston_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign X (data) and y (target)\n",
    "Make sure the data is in the appropriate shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set up data for modeling\n",
    "X_5K = boston_clean[['Bib','Age','Official Time Duration', 'F', 'M', 'Temp (F)']]\n",
    "y_5K = boston_clean['5K Duration'].values.reshape(-1, 1)\n",
    "print(X_5K.shape, y_5K.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62193e4c8caef9c5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_5K, X_test_5K, y_train_5K, y_test_5K = train_test_split(X_5K, y_5K, random_state=29)\n",
    "\n",
    "X_train_5K.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a `StandardScaler` model and fit it to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a885840c1f62d274",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# X_scaler = StandardScaler().fit(X_train)\n",
    "# y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "### Transform the training and testing data using the your `StandardScaler` models created above\n",
    "\n",
    "# X_train_scaled = X_scaler.transform(X_train)\n",
    "# X_test_scaled = X_scaler.transform(X_test)\n",
    "# y_train_scaled = y_scaler.transform(y_train)\n",
    "# y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a LinearRegression model and fit it to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4df70e615bb36ac1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_5K = LinearRegression()\n",
    "model_5K.fit(X_train_5K, y_train_5K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_5K = model_5K.predict(X_test_5K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions is an array of predicted values\n",
    "print(predictions_5K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame({'Bib':[25000], 'Age':[42],'Official Time Duration':[22175], 'F':[0], 'M':[1],'Temp (F)':[65]})\n",
    "model_5K.predict(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the residual plot for the predictions on the scaled training and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ec6532d8dc790021",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(model_5K.predict(X_train_5K), model_5K.predict(X_train_5K) - y_train_5K, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model_5K.predict(X_test_5K), model_5K.predict(X_test_5K) - y_test_5K, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_5K.min(), xmax=y_test_5K.max())\n",
    "plt.title(\"Residual Plot for 5K\")\n",
    "plt.savefig('model_5k.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate MSE and $R^2$ for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-deb1d9b663c1883f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Used X_test_5K, y_test_5K, and model.predict(X_test_5K) to calculate MSE and R2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test_5K, predictions_5K)\n",
    "r2 = model_5K.score(X_test_5K, y_test_5K)\n",
    "\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")\n",
    "\n",
    "# create lists of MSE and r2 values for each model\n",
    "boston_r2=[]\n",
    "boston_mse=[]\n",
    "boston_models = []\n",
    "\n",
    "boston_models.append('5K')\n",
    "boston_mse.append(MSE)\n",
    "boston_r2.append(r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a pickle file\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(model_5K, 'model_5K.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To save the model without the training data, in order to make predictions without re-training the model\n",
    "# # Source: https://www.geeksforgeeks.org/saving-a-machine-learning-model/\n",
    "\n",
    "# import pickle\n",
    "# from sklearn.externals import joblib \n",
    "  \n",
    "# # Save the model as a pickle in a file \n",
    "# joblib.dump(model_5K, 'model_5K.pkl')\n",
    "  \n",
    "# # Load the model from the file \n",
    "# model_5K_from_joblib = joblib.load('model_5K.pkl')  \n",
    "  \n",
    "# # Use the loaded model to make predictions \n",
    "# model_5K_from_joblib.predict(X_test_5K) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO model\n",
    "\n",
    "performs feature selection by reducing small coefficient values to absolute zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1dbfa38f409ceb7c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Note: Use an alpha of .01 when creating the model for this activity\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=.01).fit(X_train_5K, y_train_5K)\n",
    "\n",
    "predictions = lasso.predict(X_test_5K)\n",
    "\n",
    "MSE = mean_squared_error(y_test_5K, predictions_5K)\n",
    "r2 = lasso.score(X_test_5K, y_test_5K)\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge model\n",
    "\n",
    "reduces multicollinearity\n",
    "create plot to show differences in coefficient values\n",
    "use code from here: https://www.analyticsvidhya.com/blog/2017/06/a-comprehensive-guide-for-linear-ridge-and-lasso-regression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d7adb5db2fc7b236",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Note: Use an alpha of .01 when creating the model for this activity\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_5K = Ridge(alpha=.01).fit(X_train_5K, y_train_5K)\n",
    "\n",
    "predictions_5K = ridge_5K.predict(X_test_5K)\n",
    "\n",
    "MSE = mean_squared_error(y_test_5K, predictions)\n",
    "r2 = ridge_5K.score(X_test_5K, y_test_5K)\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5b0241abbdaa88e9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Note: Use an alpha of .01 when creating the model for this activity\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elasticnet_5K = ElasticNet(alpha=.01).fit(X_train_5K, y_train_5K)\n",
    "\n",
    "predictions_5K = elasticnet_5K.predict(X_test_5K)\n",
    "\n",
    "MSE = mean_squared_error(y_test_5K, predictions)\n",
    "r2 = elasticnet_5K.score(X_test_5K, y_test_5K)\n",
    "\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the model without the Bib numbers as a feature to test if Bib numbers are helpful\n",
    "\n",
    "### set up data for modeling\n",
    "X_nobib = boston_clean[['Age','Official Time Duration', 'F', 'M', 'Temp (F)']]\n",
    "y_nobib = boston_clean['5K Duration'].values.reshape(-1, 1)\n",
    "print(X_nobib.shape, y_nobib.shape)\n",
    "\n",
    "# split the data into test and train subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_nobib, X_test_nobib, y_train_nobib, y_test_nobib = train_test_split(X_nobib, y_nobib, random_state=29)\n",
    "# X_train_nobib.head()\n",
    "\n",
    "# Create a linear regression model and fit it to the training data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model_nobib = LinearRegression()\n",
    "model_nobib.fit(X_train_nobib, y_train_nobib)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "predictions_nobib = model_nobib.predict(X_test_nobib)\n",
    "\n",
    "# Plot the residuals\n",
    "\n",
    "plt.scatter(model_nobib.predict(X_train_nobib), model_nobib.predict(X_train_nobib) - y_train_nobib, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model_nobib.predict(X_test_nobib), model_nobib.predict(X_test_nobib) - y_test_nobib, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_nobib.min(), xmax=y_test_nobib.max())\n",
    "plt.title(\"Residual Plot No Bib Model\")\n",
    "plt.savefig('model_nonbib.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used X_test, y_test, and model.predict(X_test) to calculate MSE and R2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test_nobib, predictions)\n",
    "r2 = model_nobib.score(X_test_nobib, y_test_nobib)\n",
    "\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")\n",
    "\n",
    "# Model built without Bib numbers has a smaller R2 value, so Bib numbers was helping model predictions\n",
    "\n",
    "# create lists of MSE and r2 values for each model\n",
    "\n",
    "# boston_models.append('nobib')\n",
    "# boston_mse.append(MSE)\n",
    "# boston_r2.append(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the model with the Bib numbers as a feature and for the 5K split times to predict 10K time\n",
    "\n",
    "### set up data for modeling\n",
    "X_10K = boston_clean[['Bib', 'Age','Official Time Duration', 'F', 'M', 'Temp (F)', '5K Duration']]\n",
    "y_10K = boston_clean['10K Duration'].values.reshape(-1, 1)\n",
    "print(X_10K.shape, y_10K.shape)\n",
    "\n",
    "# split the data into test and train subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_10K, X_test_10K, y_train_10K, y_test_10K = train_test_split(X_10K, y_10K, random_state=29)\n",
    "# X_train_5K.head()\n",
    "\n",
    "# Create a linear regression model and fit it to the training data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model_10K = LinearRegression()\n",
    "model_10K.fit(X_train_10K, y_train_10K)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "predictions_10K = model_10K.predict(X_test_10K)\n",
    "\n",
    "# Plot the residuals\n",
    "\n",
    "plt.scatter(model_10K.predict(X_train_10K), model_10K.predict(X_train_10K) - y_train_10K, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model_10K.predict(X_test_10K), model_10K.predict(X_test_10K) - y_test_10K, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_10K.min(), xmax=y_test_10K.max())\n",
    "plt.title(\"Residual Plot 10K\")\n",
    "plt.savefig('model_10k.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_10K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used X_test, y_test, and model.predict(X_test) to calculate MSE and R2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test_10K, predictions_10K)\n",
    "r2 = model_10K.score(X_test_10K, y_test_10K)\n",
    "\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")\n",
    "\n",
    "# create lists of MSE and r2 values for each model\n",
    "\n",
    "boston_models.append('10K')\n",
    "boston_mse.append(MSE)\n",
    "boston_r2.append(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as pickle file\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(model_10K, 'model_10K.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the model with the Bib numbers as a feature and for the 5K and 10K split times to predict 15K time\n",
    "\n",
    "### set up data for modeling\n",
    "X_15K = boston_clean[['Bib', 'Age','Official Time Duration', 'F', 'M', 'Temp (F)', '5K Duration', '10K Duration']]\n",
    "y_15K = boston_clean['15K Duration'].values.reshape(-1, 1)\n",
    "print(X_15K.shape, y_15K.shape)\n",
    "\n",
    "# split the data into test and train subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_15K, X_test_15K, y_train_15K, y_test_15K = train_test_split(X_15K, y_15K, random_state=29)\n",
    "# X_train_15K.head()\n",
    "\n",
    "# Create a linear regression model and fit it to the training data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model_15K = LinearRegression()\n",
    "model_15K.fit(X_train_15K, y_train_15K)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "predictions_15K = model_15K.predict(X_test_15K)\n",
    "\n",
    "# Plot the residuals\n",
    "\n",
    "plt.scatter(model_15K.predict(X_train_15K), model_15K.predict(X_train_15K) - y_train_15K, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model_15K.predict(X_test_15K), model_15K.predict(X_test_15K) - y_test_15K, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_15K.min(), xmax=y_test_15K.max())\n",
    "plt.title(\"Residual Plot 15K\")\n",
    "plt.savefig('model_15k.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used X_test, y_test, and model.predict(X_test) to calculate MSE and R2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test_15K, predictions_15K)\n",
    "r2 = model_15K.score(X_test_15K, y_test_15K)\n",
    "\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")\n",
    "\n",
    "# create lists of MSE and r2 values for each model\n",
    "\n",
    "boston_models.append('15K')\n",
    "boston_mse.append(MSE)\n",
    "boston_r2.append(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as pickle file\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(model_15K, 'model_15K.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the model with the Bib numbers as a feature and for the 5K, 10K and 15K split times to predict 20K time\n",
    "\n",
    "### set up data for modeling\n",
    "X_20K = boston_clean[['Bib', 'Age','Official Time Duration', 'F', 'M', 'Temp (F)', '5K Duration', '10K Duration', '15K Duration']]\n",
    "y_20K = boston_clean['20K Duration'].values.reshape(-1, 1)\n",
    "print(X_20K.shape, y_20K.shape)\n",
    "\n",
    "# split the data into test and train subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_20K, X_test_20K, y_train_20K, y_test_20K = train_test_split(X_20K, y_20K, random_state=29)\n",
    "# X_train_20K.head()\n",
    "\n",
    "# Create a linear regression model and fit it to the training data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model_20K = LinearRegression()\n",
    "model_20K.fit(X_train_20K, y_train_20K)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "predictions_20K = model_20K.predict(X_test_20K)\n",
    "\n",
    "# Plot the residuals\n",
    "\n",
    "plt.scatter(model_20K.predict(X_train_20K), model_20K.predict(X_train_20K) - y_train_20K, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model_20K.predict(X_test_20K), model_20K.predict(X_test_20K) - y_test_20K, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_20K.min(), xmax=y_test_20K.max())\n",
    "plt.title(\"Residual Plot 20K\")\n",
    "plt.savefig('model_20k.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used X_test, y_test, and model.predict(X_test) to calculate MSE and R2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test_20K, predictions_20K)\n",
    "r2 = model_20K.score(X_test_20K, y_test_20K)\n",
    "\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")\n",
    "\n",
    "# create lists of MSE and r2 values for each model\n",
    "\n",
    "boston_models.append('20K')\n",
    "boston_mse.append(MSE)\n",
    "boston_r2.append(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as pickle file\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(model_20K, 'model_20K.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the model with the Bib numbers as a feature and for the 5K, 10K 15K and 20K split times to predict Half marathon time\n",
    "\n",
    "### set up data for modeling\n",
    "X_Half = boston_clean[['Bib', 'Age','Official Time Duration', 'F', 'M', 'Temp (F)', '5K Duration', '10K Duration', '15K Duration', '20K Duration']]\n",
    "y_Half = boston_clean['Half Duration'].values.reshape(-1, 1)\n",
    "print(X_Half.shape, y_Half.shape)\n",
    "\n",
    "# split the data into test and train subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_Half, X_test_Half, y_train_Half, y_test_Half = train_test_split(X_Half, y_Half, random_state=29)\n",
    "# X_train_Half.head()\n",
    "\n",
    "# Create a linear regression model and fit it to the training data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model_Half = LinearRegression()\n",
    "model_Half.fit(X_train_Half, y_train_Half)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "predictions_Half = model_Half.predict(X_test_Half)\n",
    "\n",
    "# Plot the residuals\n",
    "\n",
    "plt.scatter(model_Half.predict(X_train_Half), model_Half.predict(X_train_Half) - y_train_Half, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model_Half.predict(X_test_Half), model_Half.predict(X_test_Half) - y_test_Half, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_Half.min(), xmax=y_test_Half.max())\n",
    "plt.title(\"Residual Plot Half Marathon\")\n",
    "plt.savefig('model_Half.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used X_test, y_test, and model.predict(X_test) to calculate MSE and R2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test_Half, predictions_Half)\n",
    "r2 = model_Half.score(X_test_Half, y_test_Half)\n",
    "\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")\n",
    "\n",
    "# create lists of MSE and r2 values for each model\n",
    "\n",
    "boston_models.append('Half')\n",
    "boston_mse.append(MSE)\n",
    "boston_r2.append(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as pickle file\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(model_Half, 'model_Half.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the model with the Bib numbers as a feature and for the 5K, 10K 15K 20K and Half split times to predict 25K time\n",
    "\n",
    "### set up data for modeling\n",
    "X_25K = boston_clean[['Bib', 'Age','Official Time Duration', 'F', 'M', 'Temp (F)', '5K Duration', '10K Duration', '15K Duration', '20K Duration', 'Half Duration']]\n",
    "y_25K = boston_clean['25K Duration'].values.reshape(-1, 1)\n",
    "print(X_25K.shape, y_25K.shape)\n",
    "\n",
    "# split the data into test and train subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_25K, X_test_25K, y_train_25K, y_test_25K = train_test_split(X_25K, y_25K, random_state=29)\n",
    "# X_train_25K.head()\n",
    "\n",
    "# Create a linear regression model and fit it to the training data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model_25K = LinearRegression()\n",
    "model_25K.fit(X_train_25K, y_train_25K)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "predictions_25K = model_25K.predict(X_test_25K)\n",
    "\n",
    "# Plot the residuals\n",
    "\n",
    "plt.scatter(model_25K.predict(X_train_25K), model_25K.predict(X_train_25K) - y_train_25K, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model_25K.predict(X_test_25K), model_25K.predict(X_test_25K) - y_test_25K, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_25K.min(), xmax=y_test_25K.max())\n",
    "plt.title(\"Residual Plot 25K\")\n",
    "plt.savefig('model_25k.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used X_test, y_test, and model.predict(X_test) to calculate MSE and R2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test_25K, predictions_25K)\n",
    "r2 = model_25K.score(X_test_25K, y_test_25K)\n",
    "\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")\n",
    "\n",
    "# create lists of MSE and r2 values for each model\n",
    "\n",
    "boston_models.append('25K')\n",
    "boston_mse.append(MSE)\n",
    "boston_r2.append(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as pickle file\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(model_25K, 'model_25K.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the model with the Bib numbers as a feature and for the 5K, 10K 15K 20K 25K and half split times to predict 30K time\n",
    "\n",
    "### set up data for modeling\n",
    "X_30K = boston_clean[['Bib', 'Age','Official Time Duration', 'F', 'M', 'Temp (F)', '5K Duration', '10K Duration', '15K Duration', '20K Duration','Half Duration', '25K Duration']]\n",
    "y_30K = boston_clean['30K Duration'].values.reshape(-1, 1)\n",
    "print(X_30K.shape, y_30K.shape)\n",
    "\n",
    "# split the data into test and train subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_30K, X_test_30K, y_train_30K, y_test_30K = train_test_split(X_30K, y_30K, random_state=29)\n",
    "# X_train_30K.head()\n",
    "\n",
    "# Create a linear regression model and fit it to the training data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model_30K = LinearRegression()\n",
    "model_30K.fit(X_train_30K, y_train_30K)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "predictions_30K = model_30K.predict(X_test_30K)\n",
    "\n",
    "# Plot the residuals\n",
    "\n",
    "plt.scatter(model_30K.predict(X_train_30K), model_30K.predict(X_train_30K) - y_train_30K, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model_30K.predict(X_test_30K), model_30K.predict(X_test_30K) - y_test_30K, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_30K.min(), xmax=y_test_30K.max())\n",
    "plt.title(\"Residual Plot 30K\")\n",
    "plt.savefig('model_30k.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used X_test, y_test, and model.predict(X_test) to calculate MSE and R2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test_30K, predictions_30K)\n",
    "r2 = model_30K.score(X_test_30K, y_test_30K)\n",
    "\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")\n",
    "\n",
    "# create lists of MSE and r2 values for each model\n",
    "\n",
    "boston_models.append('30K')\n",
    "boston_mse.append(MSE)\n",
    "boston_r2.append(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as pickle file\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(model_30K, 'model_30K.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the model with the Bib numbers as a feature and for the 5K, 10K 15K 20K 25K half and 30K split times to predict 35K time\n",
    "\n",
    "### set up data for modeling\n",
    "X_35K = boston_clean[['Bib', 'Age','Official Time Duration', 'F', 'M', 'Temp (F)', '5K Duration', '10K Duration', '15K Duration', '20K Duration', 'Half Duration','25K Duration',  '30K Duration']]\n",
    "y_35K = boston_clean['35K Duration'].values.reshape(-1, 1)\n",
    "print(X_30K.shape, y_30K.shape)\n",
    "\n",
    "# split the data into test and train subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_35K, X_test_35K, y_train_35K, y_test_35K = train_test_split(X_35K, y_35K, random_state=29)\n",
    "# X_train_30K.head()\n",
    "\n",
    "# Create a linear regression model and fit it to the training data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model_35K = LinearRegression()\n",
    "model_35K.fit(X_train_35K, y_train_35K)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "predictions_35K = model_35K.predict(X_test_35K)\n",
    "\n",
    "# Plot the residuals\n",
    "\n",
    "plt.scatter(model_35K.predict(X_train_35K), model_35K.predict(X_train_35K) - y_train_35K, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model_35K.predict(X_test_35K), model_35K.predict(X_test_35K) - y_test_35K, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_35K.min(), xmax=y_test_35K.max())\n",
    "plt.title(\"Residual Plot 35K\")\n",
    "plt.savefig('model_35k.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used X_test, y_test, and model.predict(X_test) to calculate MSE and R2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test_35K, predictions_35K)\n",
    "r2 = model_35K.score(X_test_35K, y_test_35K)\n",
    "\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")\n",
    "\n",
    "# create lists of MSE and r2 values for each model\n",
    "\n",
    "boston_models.append('35K')\n",
    "boston_mse.append(MSE)\n",
    "boston_r2.append(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as pickle file\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(model_35K, 'model_35K.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the model with the Bib numbers as a feature and for the 5K, 10K 15K 20K 25K, half and 35K split times to predict 40K time\n",
    "\n",
    "### set up data for modeling\n",
    "X_40K = boston_clean[['Bib', 'Age','Official Time Duration', 'F', 'M', 'Temp (F)', '5K Duration', '10K Duration', '15K Duration', '20K Duration',  'Half Duration', '25K Duration', '30K Duration','35K Duration']]\n",
    "y_40K = boston_clean['40K Duration'].values.reshape(-1, 1)\n",
    "print(X_40K.shape, y_40K.shape)\n",
    "\n",
    "# split the data into test and train subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_40K, X_test_40K, y_train_40K, y_test_40K = train_test_split(X_40K, y_40K, random_state=29)\n",
    "# X_train_40K.head()\n",
    "\n",
    "# Create a linear regression model and fit it to the training data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model_40K = LinearRegression()\n",
    "model_40K.fit(X_train_40K, y_train_40K)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "predictions_40K = model_40K.predict(X_test_40K)\n",
    "\n",
    "# Plot the residuals\n",
    "\n",
    "plt.scatter(model_40K.predict(X_train_40K), model_40K.predict(X_train_40K) - y_train_40K, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model_40K.predict(X_test_40K), model_40K.predict(X_test_40K) - y_test_40K, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_40K.min(), xmax=y_test_40K.max())\n",
    "plt.title(\"Residual Plot 40K\")\n",
    "plt.savefig('model_40k.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used X_test, y_test, and model.predict(X_test) to calculate MSE and R2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test_40K, predictions_40K)\n",
    "r2 = model_40K.score(X_test_40K, y_test_40K)\n",
    "\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")\n",
    "\n",
    "# create lists of MSE and r2 values for each model\n",
    "\n",
    "boston_models.append('40K')\n",
    "boston_mse.append(MSE)\n",
    "boston_r2.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as pickle file\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(model_40K, 'model_40K.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the model with the Bib numbers as a feature and for the 5K, 10K 15K 20K 25K, half, 35K and 40K split times to predict Final time\n",
    "\n",
    "### set up data for modeling\n",
    "X_Final = boston_clean[['Bib', 'Age', 'F', 'M', 'Temp (F)', '5K Duration', '10K Duration', '15K Duration', '20K Duration','Half Duration', '25K Duration', '30K Duration', '35K Duration', '40K Duration']]\n",
    "y_Final = boston_clean['Official Time Duration'].values.reshape(-1, 1)\n",
    "print(X_Final.shape, y_Final.shape)\n",
    "\n",
    "# split the data into test and train subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_Final, X_test_Final, y_train_Final, y_test_Final = train_test_split(X_Final, y_Final, random_state=29)\n",
    "# X_train_Final.head()\n",
    "\n",
    "# Create a linear regression model and fit it to the training data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model_Final = LinearRegression()\n",
    "model_Final.fit(X_train_Final, y_train_Final)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "predictions_Final = model_Final.predict(X_test_Final)\n",
    "\n",
    "# Plot the residuals\n",
    "\n",
    "plt.scatter(model_Final.predict(X_train_Final), model_Final.predict(X_train_Final) - y_train_Final, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model_Final.predict(X_test_Final), model_Final.predict(X_test_Final) - y_test_Final, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_Final.min(), xmax=y_test_Final.max())\n",
    "plt.title(\"Residual Plot Final\")\n",
    "plt.savefig('model_Final.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used X_test, y_test, and model.predict(X_test) to calculate MSE and R2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test_Final, predictions_Final)\n",
    "r2 = model_Final.score(X_test_Final, y_test_Final)\n",
    "\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")\n",
    "\n",
    "# create lists of MSE and r2 values for each model\n",
    "\n",
    "boston_models.append('Final')\n",
    "boston_mse.append(MSE)\n",
    "boston_r2.append(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as pickle file\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(model_Final, 'model_Final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ec6532d8dc790021",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "boston_residuals_df=pd.DataFrame({\n",
    "    'boston_models':boston_models,\n",
    "    'boston_mse':boston_mse,\n",
    "    'boston_r2':boston_r2\n",
    "})\n",
    "boston_residuals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the residuals of each model\n",
    "\n",
    "plt.scatter(boston_residuals_df['boston_models'], boston_mse, c=\"red\", label=\"MSE\")\n",
    "\n",
    "# plt.scatter(model_Final.predict(X_test_Final), model_Final.predict(X_test_Final) - y_test_Final, c=\"orange\", label=\"Testing Data\")\n",
    "# plt.legend()\n",
    "# plt.hlines(y=0, xmin=y_test_Final.min(), xmax=y_test_Final.max())\n",
    "plt.title(\"Mean Square Error for each model\")\n",
    "plt.savefig('MSE.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(boston_residuals_df['boston_models'], boston_r2, c=\"blue\", label=\"R2\")\n",
    "# plt.legend()\n",
    "plt.title(\"R2 for each model\")\n",
    "plt.savefig('R2.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_females=boston_clean.loc[boston_clean['F'] == 1]\n",
    "boston_females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the model with ONLY female runners, and  features of the 5K, 10K 15K 20K 25K, half and 35K split times to predict 40K time\n",
    "\n",
    "### set up data for modeling\n",
    "X_F40K = boston_females[['Bib', 'Age','Official Time Duration', 'F', 'M', 'Temp (F)', '5K Duration', '10K Duration', '15K Duration', '20K Duration','Half Duration', '25K Duration', '30K Duration', '35K Duration']]\n",
    "y_F40K = boston_females['40K Duration'].values.reshape(-1, 1)\n",
    "print(X_F40K.shape, y_F40K.shape)\n",
    "\n",
    "# split the data into test and train subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_F40K, X_test_F40K, y_train_F40K, y_test_F40K = train_test_split(X_F40K, y_F40K, random_state=29)\n",
    "# X_train_F40K.head()\n",
    "\n",
    "# Create a linear regression model and fit it to the training data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model_F40K = LinearRegression()\n",
    "model_F40K.fit(X_train_F40K, y_train_F40K)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "predictions_F40K = model_F40K.predict(X_test_F40K)\n",
    "\n",
    "# Plot the residuals\n",
    "\n",
    "plt.scatter(model_F40K.predict(X_train_F40K), model_F40K.predict(X_train_F40K) - y_train_F40K, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model_F40K.predict(X_test_F40K), model_F40K.predict(X_test_F40K) - y_test_F40K, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_F40K.min(), xmax=y_test_F40K.max())\n",
    "plt.title(\"Residual Plot Female Runners 40K\")\n",
    "plt.savefig('model_F40K.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used X_test, y_test, and model.predict(X_test) to calculate MSE and R2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test_F40K, predictions_F40K)\n",
    "r2 = model_F40K.score(X_test_F40K, y_test_F40K)\n",
    "\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")\n",
    "\n",
    "# create lists of MSE and r2 values for each model\n",
    "\n",
    "# boston_models.append('F40K')\n",
    "# boston_mse.append(MSE)\n",
    "# boston_r2.append(r2)\n",
    "\n",
    "# boston_residuals_df=pd.DataFrame({\n",
    "#     'boston_models':boston_models,\n",
    "#     'boston_mse':boston_mse,\n",
    "#     'boston_r2':boston_r2\n",
    "# })\n",
    "boston_residuals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(boston_residuals_df['boston_models'], boston_r2, c=\"blue\", label=\"R2\")\n",
    "# plt.legend()\n",
    "plt.title(\"R2 for each model\")\n",
    "plt.savefig('R2.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Univariate Density Plots\n",
    "\n",
    "# # names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "# # data = pandas.read_csv(url, names=names)\n",
    "# boston_clean.plot(kind='density', subplots=True, layout=(6,3), sharex=False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
